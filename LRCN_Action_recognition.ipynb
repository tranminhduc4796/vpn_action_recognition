{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LRCN_Video_Classification_NTU_RGB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GRP4G7wovybz",
        "y46pB1JqxHsP",
        "8acA5JORxS2u",
        "bIQxxOFc0CVH",
        "33WHvDwvC4th"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy2Brf-WlCma"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDjngapj134v",
        "outputId": "3af7a534-85ab-4b10-892c-03077fddc4d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtY8exyu3Y_4",
        "outputId": "fc614946-f393-467d-c135-c37436fa15ba"
      },
      "source": [
        "%cd /content/drive/MyDrive/DL\r\n",
        "# %cd /content/drive/MyDrive/Deep_Learning/projects"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS2yPznpvoI9"
      },
      "source": [
        "### Define label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9PIhxQewGFc"
      },
      "source": [
        "dir_label = {'A008': 'sit down',\r\n",
        "             'A009': 'stand up',\r\n",
        "             'A027': 'jump up',\r\n",
        "             'A058': 'shaking hands',\r\n",
        "             'A059': 'walking towards',\r\n",
        "             'A060': 'walking apart'}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRP4G7wovybz"
      },
      "source": [
        "### Check data NTU_RGB_video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chzM2UfK4-3N",
        "outputId": "60b2f070-7709-458b-8414-1181e3ab1b0d"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "root = os.getcwd()\r\n",
        "\r\n",
        "list_dir = os.listdir('data/NTU_RGB_video')\r\n",
        "\r\n",
        "print(len(list_dir)) # 5679\r\n",
        "print(list_dir[0])\r\n",
        "\r\n",
        "count_lb = {}\r\n",
        "\r\n",
        "for f in list_dir:\r\n",
        "  lb = f[-4:]\r\n",
        "  if lb in count_lb:\r\n",
        "    count_lb[lb] +=1\r\n",
        "  else:\r\n",
        "    count_lb[lb] =1\r\n",
        "print(count_lb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5679\n",
            "S002C002P012R001A059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y46pB1JqxHsP"
      },
      "source": [
        "### Select video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVoDg8U4wH3s"
      },
      "source": [
        "# create data_file:\r\n",
        "import os\r\n",
        "\r\n",
        "data = []\r\n",
        "path = 'data/NTU_RGB_video'\r\n",
        "list_dir = os.listdir(path)\r\n",
        "count_label_split = {'A008':0,\r\n",
        "             'A009': 0,\r\n",
        "             'A027': 0,\r\n",
        "             'A058': 0,\r\n",
        "             'A059': 0,\r\n",
        "             'A060': 0}\r\n",
        "\r\n",
        "for video in list_dir:\r\n",
        "    \r\n",
        "    item1 = video[-4:]\r\n",
        "    count_label_split[item1] += 1\r\n",
        "    if count_label_split[item1] <= 100:\r\n",
        "      item0 = 'train'\r\n",
        "    else:\r\n",
        "      if (count_label_split[item1] > 100) and count_label_split[item1] <=120:\r\n",
        "        item0 = 'test'\r\n",
        "      else:\r\n",
        "        continue\r\n",
        "    \r\n",
        "    item2 = os.path.join(path, video)\r\n",
        "    list_frame = os.listdir(item2)\r\n",
        "    item3 = len(list_frame)\r\n",
        "    data.append([item0, item1, item2, item3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8acA5JORxS2u"
      },
      "source": [
        "###### Copy to /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAxdL24J5m_i"
      },
      "source": [
        "list_video = []\r\n",
        "for video in data:\r\n",
        "  list_video.append(video[2])\r\n",
        "\r\n",
        "with open('sample.txt','w') as f:\r\n",
        "  for video in list_video:\r\n",
        "    f.write(video + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKOykb836an2"
      },
      "source": [
        "!cp /content/drive/MyDrive/Deep_Learning/projects/sample.txt /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JKpTvTl7uXj"
      },
      "source": [
        "# cd data/NTU_RGB_video\r\n",
        "\r\n",
        "cat /content/sample.txt | zip -r -@ /content/video.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrb7EsSMRGf2"
      },
      "source": [
        "# !cp /content/video.zip /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIQxxOFc0CVH"
      },
      "source": [
        "###### Unzip data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXuVchYEFigI"
      },
      "source": [
        "# !wget https://doc-0c-a4-docs.googleusercontent.com/docs/securesc/te2u4l8ej0iiqbscl2toam7stk0hfjsk/v5ubhkr928er8adid9bo57th34hionsd/1610597325000/00977165141162365489/00977165141162365489/1I9SAiRfMBogjol1zS9ojiV9hUE5DE_lu?e=download&authuser=0&nonce=qatei0pk9s7jg&user=00977165141162365489&hash=kjjge5fgcbg9hlu3n2o43lu4mpengv5j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUugmC5ATf3M"
      },
      "source": [
        "# !unzip video.zip -d /content/data\r\n",
        "!unzip video.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33WHvDwvC4th"
      },
      "source": [
        "###### Save path file to data_file.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21HiaByzzfeb"
      },
      "source": [
        "# import pandas as pd\r\n",
        "\r\n",
        "# my_df = pd.DataFrame(data)\r\n",
        "# my_df.to_csv('data_file.csv', index=False, header=False)\r\n",
        "\r\n",
        "import csv\r\n",
        "\r\n",
        "with open(\"data_file.csv\", \"w\", newline=\"\") as f:\r\n",
        "    writer = csv.writer(f)\r\n",
        "    writer.writerows(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaO4znU51EaH"
      },
      "source": [
        "# splitted_file = np.split(padded_file, self.step)\r\n",
        "#             splitted_file = np.asarray(splitted_file)\r\n",
        "#             row, col, width = splitted_file.shape\r\n",
        "#             sampled_file = []\r\n",
        "#             for k in range(0, self.step):\r\n",
        "#                 c = np.random.choice(col, 1)\r\n",
        "#                 sampled_file.append(splitted_file[k, c, :])\r\n",
        "#             sampled_file = np.asarray(sampled_file)\r\n",
        "#             X[i,] = np.squeeze(sampled_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvtAlR27DtL1"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LjPYHDm4LAM"
      },
      "source": [
        "#### If using TPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6g1VN74tRm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10630bd2-3828-435a-eade-0aa47f0a85a5"
      },
      "source": [
        "# import tensorflow as tf\r\n",
        "# import os\r\n",
        "\r\n",
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "# # This is the TPU initialization code that has to be at the beginning.\r\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "# strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n",
        "\r\n",
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "print(\"Tensorflow version \" + tf.__version__)\r\n",
        "\r\n",
        "try:\r\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\r\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\r\n",
        "except ValueError:\r\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\r\n",
        "\r\n",
        "tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.0\n",
            "Running on TPU  ['10.46.104.242:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.46.104.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.46.104.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.46.104.242:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.46.104.242:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTw_4d-2Dxd5"
      },
      "source": [
        "#### Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkTBQzSiwNU1"
      },
      "source": [
        "\"\"\"\n",
        "Process an image that we can pass to our networks.\n",
        "\"\"\"\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def process_image(image, target_shape):\n",
        "    \"\"\"Given an image, process it and return the array.\"\"\"\n",
        "    # Load the image.\n",
        "    h, w, _ = target_shape\n",
        "    image = load_img(image, target_size=(h, w))\n",
        "\n",
        "    # Turn it into numpy, normalize and return.\n",
        "    img_arr = img_to_array(image)\n",
        "    x = (img_arr / 255.).astype(np.float32)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Class for managing our data.\n",
        "\"\"\"\n",
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import os.path\n",
        "import sys\n",
        "import operator\n",
        "import threading\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "class threadsafe_iterator:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with self.lock:\n",
        "            return next(self.iterator)\n",
        "\n",
        "def threadsafe_generator(func):\n",
        "    \"\"\"Decorator\"\"\"\n",
        "    def gen(*a, **kw):\n",
        "        return threadsafe_iterator(func(*a, **kw))\n",
        "    return gen\n",
        "\n",
        "class DataSet():\n",
        "\n",
        "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
        "        \"\"\"Constructor.\n",
        "        seq_length = (int) the number of frames to consider\n",
        "        class_limit = (int) number of classes to limit the data to.\n",
        "            None = no limit.\n",
        "        \"\"\"\n",
        "        self.seq_length = seq_length\n",
        "        self.class_limit = class_limit\n",
        "        self.sequence_path = os.path.join('/content/sequences')\n",
        "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
        "\n",
        "        # Get the data.\n",
        "        self.data = self.get_data()\n",
        "\n",
        "        # Get the classes.\n",
        "        self.classes = self.get_classes()\n",
        "\n",
        "        # Now do some minor data cleaning.\n",
        "        self.data = self.clean_data()\n",
        "\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    @staticmethod\n",
        "    def get_data(): # EDIT\n",
        "        \"\"\"Load our data from file.\"\"\"\n",
        "        with open(os.path.join('data_file.csv'), 'r') as fin:\n",
        "            reader = csv.reader(fin)\n",
        "            data = list(reader)\n",
        "        # ['train', 'BalanceBeam', 'v_BalanceBeam_g12_c02', '70']\n",
        "        return data\n",
        "\n",
        "        # data = []\n",
        "        # path = '/content/video/NTU_RGB_video/'\n",
        "        # list_dir = os.listdir(path)\n",
        "        # count_label_split = {'A008': 0,\n",
        "        #                      'A009': 0,\n",
        "        #                      'A027': 0,\n",
        "        #                      'A058': 0,\n",
        "        #                      'A059': 0,\n",
        "        #                      'A060': 0}\n",
        "        # for video in list_dir:\n",
        "        #     item1 = video[-4:]\n",
        "        #     count_label_split[item1] += 1\n",
        "        #     if count_label_split[item1] <= 5:\n",
        "        #         item0 = 'train'\n",
        "        #     else:\n",
        "        #         if (count_label_split[item1] > 5) and count_label_split[item1] <= 6:\n",
        "        #             item0 = 'test'\n",
        "        #         else:\n",
        "        #             continue\n",
        "        #     list_frame = os.listdir(path + video)\n",
        "        #     item2 = path + video\n",
        "        #     item3 = len(list_frame)\n",
        "        #     data.append([item0, item1, item2, item3])\n",
        "        # return data\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
        "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
        "        data_clean = []\n",
        "        for item in self.data:\n",
        "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
        "                    and item[1] in self.classes:\n",
        "                data_clean.append(item)\n",
        "\n",
        "        return data_clean\n",
        "\n",
        "    def get_classes(self): # EDIT\n",
        "        \"\"\"Extract the classes from our data. If we want to limit them,\n",
        "        only return the classes we need.\"\"\"\n",
        "        classes = []\n",
        "        # for item in self.data:\n",
        "        #     if item[1] not in classes:\n",
        "        #         classes.append(item[1])\n",
        "\n",
        "        # # Sort them.\n",
        "        # classes = sorted(classes)\n",
        "\n",
        "        # # Return.\n",
        "        # if self.class_limit is not None:\n",
        "        #     return classes[:self.class_limit]\n",
        "        # else:\n",
        "        #     return classes\n",
        "        dir_label = {'A008': 'sit down',\n",
        "                     'A009': 'stand up',\n",
        "                     'A027': 'jump up',\n",
        "                     'A058': 'shaking hands',\n",
        "                     'A059': 'walking towards',\n",
        "                     'A060': 'walking apart'}\n",
        "        classes = list(dir_label)\n",
        "        return classes\n",
        "\n",
        "    def get_class_one_hot(self, class_str):\n",
        "        \"\"\"Given a class as a string, return its number in the classes\n",
        "        list. This lets us encode and one-hot it for training.\"\"\"\n",
        "        # Encode it first.\n",
        "        label_encoded = self.classes.index(class_str)\n",
        "\n",
        "        # Now one-hot it.\n",
        "        label_hot = to_categorical(label_encoded, len(self.classes))\n",
        "\n",
        "        assert len(label_hot) == len(self.classes)\n",
        "\n",
        "        return label_hot\n",
        "\n",
        "    def split_train_test(self):\n",
        "        \"\"\"Split the data into train and test groups.\"\"\"\n",
        "        train = []\n",
        "        test = []\n",
        "        for item in self.data:\n",
        "            if item[0] == 'train':\n",
        "                train.append(item)\n",
        "            else:\n",
        "                test.append(item)\n",
        "        return train, test\n",
        "\n",
        "    def get_all_sequences_in_memory(self, train_test, data_type):\n",
        "        \"\"\"\n",
        "        This is a mirror of our generator, but attempts to load everything into\n",
        "        memory so we can train way faster.\n",
        "        \"\"\"\n",
        "        # Get the right dataset.\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
        "\n",
        "        X, y = [], []\n",
        "        for row in data:\n",
        "\n",
        "            if data_type == 'images':\n",
        "                frames = self.get_frames_for_sample(row)\n",
        "                frames = self.rescale_list(frames, self.seq_length)\n",
        "\n",
        "                # Build the image sequence\n",
        "                sequence = self.build_image_sequence(frames)\n",
        "\n",
        "            else:\n",
        "                sequence = self.get_extracted_sequence(data_type, row)\n",
        "\n",
        "                if sequence is None:\n",
        "                    print(\"Can't find sequence. Did you generate them?\")\n",
        "                    raise\n",
        "\n",
        "            X.append(sequence)\n",
        "            y.append(self.get_class_one_hot(row[1]))\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    @threadsafe_generator\n",
        "    def frame_generator(self, batch_size, train_test, data_type):\n",
        "        \"\"\"Return a generator that we can use to train on. There are\n",
        "        a couple different things we can return:\n",
        "        data_type: 'features', 'images'\n",
        "        \"\"\"\n",
        "        # Get the right dataset for the generator.\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n",
        "\n",
        "        while 1:\n",
        "            X, y = [], []\n",
        "\n",
        "            # Generate batch_size samples.\n",
        "            for _ in range(batch_size):\n",
        "                # Reset to be safe.\n",
        "                sequence = None\n",
        "\n",
        "                # Get a random sample.\n",
        "                sample = random.choice(data) # ['train', 'A059', 'data/NTU_RGB_video/S001C002P006R002A059', 93]\n",
        "\n",
        "                # Check to see if we've already saved this sequence.\n",
        "                if data_type is \"images\":\n",
        "                    # Get and resample frames.\n",
        "                    frames = self.get_frames_for_sample(sample)\n",
        "                    frames = self.rescale_list(frames, self.seq_length)\n",
        "\n",
        "                    # Build the image sequence\n",
        "                    sequence = self.build_image_sequence(frames)\n",
        "                else:\n",
        "                    # Get the sequence from disk.\n",
        "                    sequence = self.get_extracted_sequence(data_type, sample)\n",
        "\n",
        "                    if sequence is None:\n",
        "                        raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "\n",
        "                X.append(sequence)\n",
        "                y.append(self.get_class_one_hot(sample[1]))\n",
        "            yield np.array(X), np.array(y)\n",
        "\n",
        "    def build_image_sequence(self, frames):\n",
        "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
        "        return [process_image(x, self.image_shape) for x in frames]\n",
        "\n",
        "    def get_extracted_sequence(self, data_type, sample):\n",
        "        \"\"\"Get the saved extracted features.\"\"\"\n",
        "        filename = sample[2]\n",
        "        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n",
        "            '-' + data_type + '.npy')\n",
        "        if os.path.isfile(path):\n",
        "            return np.load(path)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_frames_by_filename(self, filename, data_type):\n",
        "        \"\"\"Given a filename for one of our samples, return the data\n",
        "        the model needs to make predictions.\"\"\"\n",
        "        # First, find the sample row.\n",
        "        sample = None\n",
        "        for row in self.data:\n",
        "            if row[2] == filename:\n",
        "                sample = row\n",
        "                break\n",
        "        if sample is None:\n",
        "            raise ValueError(\"Couldn't find sample: %s\" % filename)\n",
        "\n",
        "        if data_type == \"images\":\n",
        "            # Get and resample frames.\n",
        "            frames = self.get_frames_for_sample(sample)\n",
        "            frames = self.rescale_list(frames, self.seq_length)\n",
        "            # Build the image sequence\n",
        "            sequence = self.build_image_sequence(frames)\n",
        "        else:\n",
        "            # Get the sequence from disk.\n",
        "            sequence = self.get_extracted_sequence(data_type, sample)\n",
        "\n",
        "            if sequence is None:\n",
        "                raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    @staticmethod\n",
        "    def get_frames_for_sample(sample): # EDIT\n",
        "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
        "        filenames.\"\"\"\n",
        "        # path = os.path.join(sample[0], sample[1])\n",
        "        # filename = sample[2]\n",
        "        # images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
        "        # # ['train', 'BalanceBeam', 'v_BalanceBeam_g12_c02', '70']\n",
        "        # # test/RockClimbingIndoor/v_RockClimbingIndoor_g06_c03-0312.jpg\n",
        "        # return images\n",
        "\n",
        "        path = sample[2] # input: sample: ['train', 'A059', 'data/NTU_RGB_video/S001C002P002R002A059', 98]\n",
        "        images = sorted(glob.glob(path + '/' + '*jpg'))\n",
        "        return images\n",
        "\n",
        "    @staticmethod\n",
        "    def get_filename_from_image(filename):\n",
        "        parts = filename.split(os.path.sep)\n",
        "        return parts[-1].replace('.jpg', '')\n",
        "\n",
        "    @staticmethod\n",
        "    def rescale_list(input_list, size):\n",
        "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
        "        if we want a list of size 5 and we have a list of size 25, return a new\n",
        "        list of size five which is every 5th element of the origina list.\"\"\"\n",
        "        assert len(input_list) >= size\n",
        "\n",
        "        # Get the number to skip between iterations.\n",
        "        skip = len(input_list) // size\n",
        "\n",
        "        # Build our new output.\n",
        "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
        "\n",
        "        # Cut off the last one if needed.\n",
        "        return output[:size]\n",
        "\n",
        "    def print_class_from_prediction(self, predictions, nb_to_return=5):\n",
        "        \"\"\"Given a prediction, print the top classes.\"\"\"\n",
        "        # Get the prediction for each label.\n",
        "        label_predictions = {}\n",
        "        for i, label in enumerate(self.classes):\n",
        "            label_predictions[label] = predictions[i]\n",
        "\n",
        "        # Now sort them.\n",
        "        sorted_lps = sorted(\n",
        "            label_predictions.items(),\n",
        "            key=operator.itemgetter(1),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # And return the top N.\n",
        "        for i, class_prediction in enumerate(sorted_lps):\n",
        "            if i > nb_to_return - 1 or class_prediction[1] == 0.0:\n",
        "                break\n",
        "            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz1qEx-gD8Xr"
      },
      "source": [
        "#### Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqdytqZWxZKE"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, LSTM, Conv2D, MaxPooling3D, Input, Activation, TimeDistributed\n",
        "\n",
        "def add_default_block(model, kernel_filters, init, reg_lambda):\n",
        "    # conv\n",
        "    model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same')))\n",
        "    model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(Activation('relu')))\n",
        "    # conv\n",
        "    model.add(TimeDistributed(Conv2D(kernel_filters, (3, 3), padding='same')))\n",
        "    model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(Activation('relu')))\n",
        "    # max pool\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9teDcqGnxNTP"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "A collection of models we'll use to attempt to classify videos.\n",
        "\"\"\"\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM, Conv2D, MaxPooling2D, Input, Activation, TimeDistributed, BatchNormalization, Input\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "from collections import deque\n",
        "import sys\n",
        "\n",
        "\n",
        "def LRCN(input_shape=(16, 224, 224, 3), nb_classes=6, batch_size=2, initialiser='glorot_uniform', reg_lambda=0.001):\n",
        "    model = Sequential()\n",
        "\n",
        "    input_batch = Input(shape = input_shape, batch_size = batch_size)\n",
        "\n",
        "    # first (non-default) block\n",
        "    model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same'), input_shape=input_shape))\n",
        "    model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(Activation('relu')))\n",
        "    model.add(TimeDistributed(Conv2D(32, (3,3))))\n",
        "    model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(Activation('relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "    # 2nd-5th (default) blocks\n",
        "    model = add_default_block(model, 64,  init=initialiser, reg_lambda=reg_lambda)\n",
        "    model = add_default_block(model, 128, init=initialiser, reg_lambda=reg_lambda)\n",
        "    model = add_default_block(model, 256, init=initialiser, reg_lambda=reg_lambda)\n",
        "    model = add_default_block(model, 512, init=initialiser, reg_lambda=reg_lambda)\n",
        "\n",
        "    # LSTM output head\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
        "    model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwpn4M9lEPHF"
      },
      "source": [
        "#### Define hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQmODM2t3oNV",
        "outputId": "de7a20d8-abf7-4bb5-cbbd-597909c860a8"
      },
      "source": [
        "\"\"\"\n",
        "Train our RNN on extracted features or images.\n",
        "\"\"\"\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "import time\n",
        "import os.path\n",
        "\n",
        "class_limit = None\n",
        "nb_epoch = 100\n",
        "# batch_size = 16 * tpu_strategy.num_replicas_in_sync\n",
        "batch_size = 16\n",
        "seq_length = 16\n",
        "features_length=2048\n",
        "nb_classes= 6\n",
        "image_shape = (224, 224, 3)\n",
        "input_shape = (seq_length, 224, 224, 3)\n",
        "\n",
        "metrics = ['accuracy']\n",
        "if nb_classes >= 10:\n",
        "    metrics.append('top_k_categorical_accuracy')\n",
        "\n",
        "initialiser = 'glorot_uniform'\n",
        "reg_lambda  = 0.001\n",
        "\n",
        "\n",
        "# Helper: Save the model.\n",
        "checkpointer = ModelCheckpoint('lrcn-images.{epoch:03d}-{val_loss:.3f}.hdf5', verbose=1)\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tb = TensorBoard(log_dir=os.path.join('data', 'logs', 'lstm'))\n",
        "\n",
        "# Helper: Stop when we stop learning.\n",
        "early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "# Helper: Save results.\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('data', 'logs', 'lstm-training-' + \\\n",
        "    str(timestamp) + '.log'))\n",
        "\n",
        "\n",
        "# Get the data and process it.\n",
        "data = DataSet(\n",
        "            seq_length=seq_length,\n",
        "            class_limit=class_limit,\n",
        "            image_shape=image_shape\n",
        "        )\n",
        "\n",
        "# Get samples per epoch.\n",
        "# Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
        "# steps_per_epoch = (len(data.data) * 0.7) // batch_size\n",
        "steps_per_epoch = (len(data.data) ) // batch_size\n",
        "\n",
        "generator = data.frame_generator(batch_size, 'train', 'images')\n",
        "val_generator = data.frame_generator(batch_size, 'test', 'images')\n",
        "\n",
        "print(generator.__iter__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method threadsafe_iterator.__iter__ of <__main__.threadsafe_iterator object at 0x7fc1716c44e0>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH4h7ekbEddi"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Px6MmRj5ehN"
      },
      "source": [
        "##### If using TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abkbpjpFbyF-"
      },
      "source": [
        "# import tensorflow as tf\r\n",
        "# tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC9Bmj7D4YFS"
      },
      "source": [
        "##### Get model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQG5dtQUiT-V"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "start_lr = 0.00001\r\n",
        "min_lr = 0.00001\r\n",
        "# max_lr = 0.00005 * tpu_strategy.num_replicas_in_sync\r\n",
        "max_lr = 0.00005 \r\n",
        "rampup_epochs = 5\r\n",
        "sustain_epochs = 0\r\n",
        "exp_decay = .8\r\n",
        "\r\n",
        "def lrfn(epoch):\r\n",
        "  if epoch < rampup_epochs:\r\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\r\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\r\n",
        "    return max_lr\r\n",
        "  else:\r\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\r\n",
        "    \r\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry1nDXJtYaO8"
      },
      "source": [
        "# with strategy.scope():  \r\n",
        "model = LRCN(input_shape=input_shape, \r\n",
        "          nb_classes=nb_classes, \r\n",
        "          batch_size=batch_size, \r\n",
        "          initialiser=initialiser, \r\n",
        "          reg_lambda=reg_lambda)\r\n",
        "\r\n",
        "# optimizer = Adam(lr=1e-5* tpu_strategy.num_replicas_in_sync, decay=1e-6)\r\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\r\n",
        "\r\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZGOfKrzl2Nk"
      },
      "source": [
        "##### Model graph visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAzVg4C_RO1h"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\r\n",
        "plot_model(model, to_file='LRCN.png', show_shapes=False, show_layer_names=True, rankdir='TB', expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFAspDPW49rF"
      },
      "source": [
        "##### Load model from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXa-Rmc0v6p4"
      },
      "source": [
        "model = load_model('/content/drive/MyDrive/DL/lrcn-images.008-0.830.hdf5')\r\n",
        "# optimizer = Adam(lr=1e-5, decay=1e-6)\r\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2BT1mo-5LdB"
      },
      "source": [
        "##### Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P5daGCLclGG",
        "outputId": "adf42c84-e035-4450-98c0-e97ab5cfab22"
      },
      "source": [
        "history = model.fit_generator(\n",
        "          generator=generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=nb_epoch,\n",
        "          verbose=1,\n",
        "          callbacks=[tb, early_stopper, csv_logger, checkpointer, lr_callback],\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=40,\n",
        "          workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating train generator with 600 samples.\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "10/45 [=====>........................] - ETA: 1:55:28 - loss: 0.0272 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4Wn5KJkpnXr3",
        "outputId": "aabe4f32-57ab-4a86-cc54-73f8481ec972"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test..gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU8FzbW_Uv_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f20b29-257c-40fa-f233-3cfc1aa6255e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-01HUoeX7_XA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}